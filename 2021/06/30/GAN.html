<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Generative Adversarial Networks | Multiplying Matrices for a living</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Generative Adversarial Networks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The introduction blog to start in GAN world" />
<meta property="og:description" content="The introduction blog to start in GAN world" />
<link rel="canonical" href="https://theguywithblacktie.github.io/kernel/2021/06/30/GAN.html" />
<meta property="og:url" content="https://theguywithblacktie.github.io/kernel/2021/06/30/GAN.html" />
<meta property="og:site_name" content="Multiplying Matrices for a living" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-30T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-06-30T00:00:00-05:00","url":"https://theguywithblacktie.github.io/kernel/2021/06/30/GAN.html","@type":"BlogPosting","headline":"Generative Adversarial Networks","dateModified":"2021-06-30T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://theguywithblacktie.github.io/kernel/2021/06/30/GAN.html"},"description":"The introduction blog to start in GAN world","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/kernel/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://theguywithblacktie.github.io/kernel/feed.xml" title="Multiplying Matrices for a living" /><link rel="shortcut icon" type="image/x-icon" href="/kernel/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/kernel/">Multiplying Matrices for a living</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/kernel/about/">About Me</a><a class="page-link" href="/kernel/search/">Search</a><a class="page-link" href="/kernel/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Generative Adversarial Networks</h1><p class="page-description">The introduction blog to start in GAN world</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-06-30T00:00:00-05:00" itemprop="datePublished">
        Jun 30, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#background-generative-models-vs-discriminative-models">Background: Generative Models v/s Discriminative Models</a>
<ul>
<li class="toc-entry toc-h3"><a href="#discriminative-models">Discriminative Models</a></li>
<li class="toc-entry toc-h3"><a href="#generative-models">Generative Models</a></li>
<li class="toc-entry toc-h3"><a href="#generative-models-are-hard">Generative Models are hard</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#generative-adversarial-networks">Generative Adversarial Networks</a>
<ul>
<li class="toc-entry toc-h3"><a href="#discriminator">Discriminator</a></li>
<li class="toc-entry toc-h3"><a href="#generator">Generator</a></li>
<li class="toc-entry toc-h3"><a href="#gan-training">GAN Training</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#gan-mathematics">GAN Mathematics</a>
<ul>
<li class="toc-entry toc-h3"><a href="#notations-and-loss-functions">Notations and Loss Functions</a></li>
</ul>
</li>
</ul><p>We have come across various articles and posts about AI being capable of producing human like speech or generating images of non-existing people that are difficult to distinguish from real-life existence. These AI systems are built upon generative adversarial networks (GANs) - which Facebook AI research director Yann LeCun called “<em>most interesting idea in last 10 years in ML</em>” GANs were introduced in a <a href="!https://arxiv.org/abs/1406.2661">paper</a> by Ian Goodfellow and other researchers at the University of Montreal, including Yoshua Bengio, in 2014.</p>

<p>GANs’ potential for both good and evil is huge, because they can learn to mimic any distribution of data. That is, GANs can be taught to create worlds eerily similar to our own in any domain: images, music, speech, prose. They are robot artists in a sense, and their output is impressive - poignant even. But they can also be used to generate fake media content and are the technology underpinning Deepfakes.</p>

<p>To understand GANs, we need to understand generative algorithms and its counterpart discriminative algorithms.</p>

<h2 id="background-generative-models-vs-discriminative-models">
<a class="anchor" href="#background-generative-models-vs-discriminative-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background: Generative Models v/s Discriminative Models</h2>

<h3 id="discriminative-models">
<a class="anchor" href="#discriminative-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Discriminative Models</h3>
<p>Discriminative models classifies the input data; i.e. given the features of an instance of data, they predict the label or cateogry to which the data belongs. For example, given , all the words in an email (this is data instance), a discriminative model would predict whether the email is <code class="language-plaintext highlighter-rouge">spam</code> or <code class="language-plaintext highlighter-rouge">not_spam</code>. <code class="language-plaintext highlighter-rouge">spam</code> is one of the labels, and the bag of words gathered from the email are the features that constitute the input data. When this problem is expressed mathematically, the label is called as $Y$ and the features are called as $X$. The formualtion $P(Y|X)$ is used to mean “<em>the probability of y given x</em>” which in this case would translate to “the probability that an email is spam given the words it contains”.</p>

<p>So discriminative models maps features to labels. They are concerned solely with that correlation. Discriminative models directly learns the conditional distribution $P(Y|X)$.</p>

<h3 id="generative-models">
<a class="anchor" href="#generative-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generative Models</h3>
<p>On the other hand, generative models learns the joint probability distribution $P(X,Y)$ by explicitly learning $P(X|Y)$ and $P(Y)$, and then uses it to compute $P(Y|X)$ through 
Bayes rule.</p>

<p>Given a model of the joint distribution, $P(X,Y)$, marginal distribution of $X$ &amp; $Y$ can be calculated as:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>y</mi></munder><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>=</mo><mi>y</mi><mo stretchy="false">)</mo><mtext>  </mtext><mi>a</mi><mi>n</mi><mi>d</mi><mspace linebreak="newline"></mspace><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∫</mo><mi>x</mi></msub><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X) = \sum_{y}P(X, Y = y) \space \space and \\
P(Y) = \int_{x}P(Y, X = x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.4361180000000004em;vertical-align:-1.386113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.386113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.27195em;vertical-align:-0.9119499999999999em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.6105579999999999em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span>

<p>considering $X$ as continuous, hence integrating over it and $Y$ as discrete hence summing over it.</p>

<p>Either conditional distribution can be computed as:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(Y|X) = \frac{P(X,Y)}{P(X)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>

<p>Thats how, we can compute $P(Y|X)$ in generative models.</p>

<p><em>One way think about generative models from GANs perspective is that they do the opposite of discriminative models.</em> Instead of predicting labels given the features, generative models attempt to predict features given a certain label i.e. $P(X|Y)$. Understanding it from the email example, generative model tries to answer this: Assuming the given eamil is <code class="language-plaintext highlighter-rouge">spam</code>, how likely are these features? While discriminative models care about relation between $Y$ and $X$, generative models care about “how you get $X$?”</p>

<p>Formal Definitions:</p>

<ul>
  <li>A <strong>discriminative</strong> model learns a function that maps the input data <code class="language-plaintext highlighter-rouge">X</code> to some desired output class label <code class="language-plaintext highlighter-rouge">Y</code>. In probabilistic terms, they directly learn the conditional distribution <code class="language-plaintext highlighter-rouge">P(Y|X)</code>.</li>
  <li>A <strong>generative</strong> model tries to learn joint probability of the input data and labels simultaneously, i.e. <code class="language-plaintext highlighter-rouge">P(X,Y)</code>. This is converted to <code class="language-plaintext highlighter-rouge">P(X|Y)</code> for classification via Bayes rule, but the generative ability could be used for something else as well, such as creating new <code class="language-plaintext highlighter-rouge">(X,Y)</code> sample.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The word "generative" in generative models does not mean that the model generates actual new data additionally
to the dataset. It refers to the nature of the theoretical model, in the sense that the generative approach
assumes that any sample of data in generated from some distribution, and it tries to estimate this 
distribution. Once the distribution is estimated the model could be used to actually generate instances following
this distribution.
</code></pre></div></div>

<p>Both these models are used in supervised learning where one wants to learn a rule that maps input $X$ to output $Y$. Some argues that the discriminative models are better as they directly models the quantity we care about i.e. $Y$ and hence no efforts are spent on modelling the input $X$. However, generative models has its own advantages such as capability of dealing with missing data. Since, generative models concerns about $P(X,Y)$ and $P(X)$ at the same time in order to predict $P(Y|X)$, they have less <strong>degree of freedom</strong> as compared to discriminative models. So generative models are more robust, less prone to overfitting than discriminative models.</p>

<h3 id="generative-models-are-hard">
<a class="anchor" href="#generative-models-are-hard" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generative Models are hard</h3>
<p>As explained earlier, generative models are better than discriminative models in certain aspects but they are even difficult to train. Generative models tackle a more difficult task than analogous discriminative models. Generative models have to model more.</p>

<p>A generative model for images might capture correlations like “things that look like boats are probably going to appear near things that look like water” and “eyes are unlikely to appear on foreheads”. These are very complicated distributions.</p>

<p>In contrast, a discriminative model might learn the difference between “sailboat” or “not sailboat” by just looking for a few tell-tale patterns. It could ignore many of the correlations that the generative models <strong><em>must</em></strong> get right.</p>

<p>Discriminative models try to draw boundaries in the data space, while generative models try to model how data is placed throughut the space. For example, the following diagrams shows discriminative and generative models of handwritten digits:</p>

<p><img src="/kernel/images/GAN_1.png" alt="" title="Fig: 1. Discriminative and Generative Model of handwritten digits"></p>

<p>The discriminative model tries to tell the difference between handwritten 0’s and 1’s by drawing a line in the data space. If it gets the line right, it can distinguish 0’s from 1’s without ever having to model exactly where the instances are placed in the data space on either side of the line.</p>

<p>In contrast, the generative model tries to produce convincing 1’s and 0’s by generating digits that fall close to their real counterparts in the data space. It has to model the distribution throughout the data space. GANs offer an effective way to train such rich models to resemble a real distribution.</p>

<h2 id="generative-adversarial-networks">
<a class="anchor" href="#generative-adversarial-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generative Adversarial Networks</h2>

<p>Lets dive into GANs and their working.</p>

<p>The main idea behind GANs is to have two competing neural network models. One takes noise as input and generates samples (hence called <strong>generator</strong>) wheras other model (called <strong>discriminator</strong>) receives samples from both the <em>generator</em> and the training data, and has to be able to distinguish between the two inputs. These two networks play a continuous game, where the <em>generator</em> is leaning to produce more and more realistic samples, and the <em>discriminator</em> is learning to get better and better at distinguishing generated data from the real data.</p>

<p><img src="/kernel/images/GAN_2.png" alt="" title="Fig: 2. GANs Overview"></p>

<p>Lets take an example. Lets say we are going to generate hand-written numerals like those found in the MNIST dataset, which is taken from the real world. The goal of the <em>discriminator</em> here, when shown an instance from the true MNIST dataset, is to recognize those that are authentic and belong to MNIST dataset.</p>

<p>Meanwhile, the <em>generator</em> is creating new, synthetic images just like MNIST dataset and passes it to the <em>discriminator</em>. <em>Generator</em> does so in the hope that its generated synthetic images will be deemed authentic by the <em>discriminator</em> even though they are fake. The goal of the <em>generator</em> is to generate hand-written digits not to be caught by <em>discriminator</em> for being fake. The goal of the <em>discriminator</em> is to identify images coming from the generators as fake.</p>

<p><img src="/kernel/images/GAN_3.png" alt="" title="Fig: 3. GANs Working for Images"></p>

<p>Here are the steps a GAN takes:</p>

<ul>
  <li>The generator takes in random numbers and returns an image</li>
  <li>This generated image is fed into the discriminator alongside a stream of images taken from the actual, ground-truth dataset.</li>
  <li>The discriminator takes in both real and fake images and return probabilities for whether image is fake or real.</li>
</ul>

<div class="Toast">
   <span class="Toast-icon"><svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg></span>
   <span class="Toast-content">Discriminator takes real images and fake images one after another (not simulataneously) and calculate their probabilites for being fake or real</span>
</div>

<p>So there is a double feedback loop (or two ways through which weights are updated):</p>

<ul>
  <li>The <strong>discriminator</strong> is in a feedback loop with the ground truth of the real images i.e. discriminator’s weights are updated based on its performance to detect real images as real</li>
  <li>The <strong>generator</strong> is in a feedback loop with the <strong>discriminator</strong> i.e. generator’s weights are updated based on discriminator’s performance to detect generated images as fake</li>
</ul>

<p>The analogy that is often used to understand GAN is that the <strong>generator</strong> is like a forger trying to produce some counterfeit material, and the <strong>discriminator</strong> is like the police trying to detect the forged items. <em>This setup may also seem somewhat reminiscent of reinforcement learning, where the generator is receiving a reward signal from the discriminator letting it know whether the generated data is accurate or not.</em> The key difference with GANs however is that we can backpropagate gradients from the discriminator  network back to the generator network, so the generator knows how to adapt its parameters in order to produce output data that can fool discriminator. Lets learn how loss is propagated from one <strong>discriminator</strong> network to another <strong>generator</strong> network.</p>

<h3 id="discriminator">
<a class="anchor" href="#discriminator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Discriminator</h3>
<p>The <strong>discriminator</strong> in GANs are simply a classifier. It tries to distinguish real data from the data generated by the <strong>generator</strong>. It could use any network architecture appropriate to the type of data it’s classifying. In MNIST example above, the <strong>discriminator</strong> network could be a standard convolutional network that can categorize the images fed to it; a binary classifier labelling images as real or fake.</p>

<p>As explained earlier, <strong>discriminator’s</strong> training data comes from two sources:</p>

<ul>
  <li>Real data instances taken from the real world. The <strong>discriminator</strong> uses these instances as positive examples during training.</li>
  <li>Fake data instances created by the <strong>generator</strong>. The <strong>discriminator</strong> uses these instances as negative examples during training.</li>
</ul>

<p>The <strong>discriminator</strong> connects to two loss functions. During discriminator training, the <strong>discriminator</strong> ignores the generator loss and just uses the discriminator loss. During <strong>discriminator</strong> training:</p>

<ol>
  <li>The <strong>discriminator</strong> classifies both real data and fake data (from the <strong>generator</strong>).</li>
  <li>The discriminator loss penalizes the discriminator for misclassifying a real instance as fake or a fake instance as real.</li>
  <li>The discriminator updates it weights through backpropagation from the discriminator loss through <strong>discriminator</strong> network.</li>
</ol>

<p><img src="/kernel/images/GAN_discriminator_loss.png" alt="" title="Fig: 4. Backpropagation in Discriminator Training"></p>

<h3 id="generator">
<a class="anchor" href="#generator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generator</h3>

<p>The <strong>generator</strong> part of GAN learns to create fake data by incorporating feedback from the <strong>discriminator</strong>. It learns to make the discriminator classify its output as real.</p>

<p>GAN takes random noise as its input. The <strong>generator</strong> then transforms this noise into a meaningful output. By introducing noise, we can get the GAN to produce a wide variety of data, sampling from different places in the target distribution. Experiments suggest that the distribution of noise doesn’t matter much, so we can choose something that’s easy to sample from, like a normal distribution. For convenience, the space from which the noise is sampled is usually of smaller dimension than the dimensionality of the output space.</p>

<p>A neural net is trained by altering its weights to reduce the error. In GANs, however, the <strong>generator</strong> is not directly connected to the loss that we’re trying to affect. The <strong>generator</strong> feeds into the <strong>discriminator</strong> net, and the <strong>discriminator</strong> produces the output through which loss is computed. Backpropagation adjusts weights in right direction by calculating the weight’s impact on the output. But the impact of a <strong>generators</strong> weight depends on the impact of the <strong>discriminator</strong> weight it feeds into. impact  So this extra chunk of <strong>discriminator</strong> network is included in the backpropagation that trains the <strong>generator</strong>. Backpropagation starts at the output of GAN and flows back through the discriminator into the generator.</p>

<p>At the same time, we don’t want the <strong>discriminator</strong> weights to be altering during the <strong>generator</strong> training.</p>

<p>So <strong>generator</strong> is trained in following way:</p>
<ol>
  <li>Sample random noise</li>
  <li>Produce generator output from sampled random noise</li>
  <li>Get discriminator “Real” or “Fake” classification for generator output</li>
  <li>Calculate loss from <strong>discriminator</strong> classification</li>
  <li>Backpropagate through both the <strong>discriminator</strong> and <strong>generator</strong> to obtain gradients.</li>
  <li>Use gradients to change only the generator weights.</li>
</ol>

<p><img src="/kernel/images/GAN_generator_loss.png" alt="" title="Fig: 5. Backpropagation in Generator Training"></p>

<h3 id="gan-training">
<a class="anchor" href="#gan-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>GAN Training</h3>
<p>We saw, how individually <strong>generator</strong> and <strong>discriminator</strong> train in their specific sections above. GAN as a whole is trained when both its <strong>generator</strong> and <strong>discriminator</strong> network get trains. GAN’s training proceeds in a alternating way:</p>

<ol>
  <li>The <strong>discriminator</strong> trains for one or more epochs.</li>
  <li>The <strong>generator</strong> trains for one or more epochs.</li>
  <li>Steps 1 and 2 are repeated to continue train the generator and discriminator.</li>
</ol>

<p>When <strong>discriminator</strong> network is trained, <strong>generator</strong> network is kept constant. Similarly, <strong>discriminator</strong> network is kept constant when <strong>generator</strong> network is trained. Its this back and forth of training that allows GANs to tackle intractable generative problem.</p>

<div class="Toast">
   <span class="Toast-icon"><svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg></span>
   <span class="Toast-content">As the generator improves with training, the discriminator performance gets worse which hampers generator's training</span>
</div>

<p>As the generator improves with training, the discriminator performance gets worse since the discriminator can’t easily tell the difference between real and fake. If the generator succeeds perfectly, then the discriminator has a 50% accuracy. This progression poses a problem for GAN as a whole: the <strong>discriminator</strong> feedback to <strong>generator</strong> gets less meaningful overtime. If the GAN continues training past the point when the discriminator is giving completely random feedback, then the <strong>generator</strong> starts to train on  junk feedback, and its quality may collapse.</p>

<h2 id="gan-mathematics">
<a class="anchor" href="#gan-mathematics" aria-hidden="true"><span class="octicon octicon-link"></span></a>GAN Mathematics</h2>
<p>Let us understand how GAN is trained mathematically.</p>

<p>We learnt in earlier sections how GAN can be seen as an interplay between two different models i.e. <strong>generator</strong> and <strong>discriminator</strong>. As a result, each of the model would have its own loss function. Lets define the loss function for each of the two models but before that first some <em>notations</em> for loss functions.</p>

<h3 id="notations-and-loss-functions">
<a class="anchor" href="#notations-and-loss-functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Notations and Loss Functions</h3>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>:</mo><mtext>  </mtext><mi>R</mi><mi>e</mi><mi>a</mi><mi>l</mi><mtext>  </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mtext>  </mtext><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mspace linebreak="newline"></mspace><mi>z</mi><mo>:</mo><mtext>  </mtext><mi>L</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mtext>  </mtext><mi>V</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>o</mi><mi>r</mi><mtext>  </mtext><mi>f</mi><mi>r</mi><mi>o</mi><mi>m</mi><mtext>  </mtext><mi>g</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mtext>  </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mspace linebreak="newline"></mspace><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>:</mo><mtext>  </mtext><mi>F</mi><mi>a</mi><mi>k</mi><mi>e</mi><mtext>  </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mtext>  </mtext><mi>f</mi><mi>r</mi><mi>o</mi><mi>m</mi><mtext>  </mtext><mi>g</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mspace linebreak="newline"></mspace><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>:</mo><mtext>  </mtext><mi>D</mi><mi>i</mi><mi>s</mi><mi>c</mi><mi>r</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>t</mi><mi>o</mi><msup><mi>r</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>s</mi><mtext>  </mtext><mi>e</mi><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>  </mtext><mi>o</mi><mi>f</mi><mtext>  </mtext><mi>r</mi><mi>e</mi><mi>a</mi><mi>l</mi><mtext>  </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mspace linebreak="newline"></mspace><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>:</mo><mtext>  </mtext><mi>D</mi><mi>i</mi><mi>s</mi><mi>c</mi><mi>r</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>t</mi><mi>o</mi><msup><mi>r</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>s</mi><mtext>  </mtext><mi>e</mi><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>  </mtext><mi>o</mi><mi>f</mi><mtext>  </mtext><mi>f</mi><mi>a</mi><mi>k</mi><mi>e</mi><mtext>  </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mspace linebreak="newline"></mspace><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>:</mo><mtext>  </mtext><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mtext>  </mtext><mi>b</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>e</mi><mi>e</mi><mi>n</mi><mtext> </mtext><msup><mtext> </mtext><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mtext>  </mtext><mi>a</mi><mi>n</mi><mi>d</mi><mtext> </mtext><msup><mtext> </mtext><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mspace linebreak="newline"></mspace></mrow><annotation encoding="application/x-tex">x :\space\space Real\space\space data \space\space sample\\
z :\space\space Latent \space\space Vector \space\space from \space\space generator \space\space model\\
G(z) :\space\space Fake \space\space data \space\space from \space\space generator\\
D(x) :\space\space Discriminator's \space\space evaluation \space\space of \space\space real \space\space data\\
D(G(z)) :\space\space Discriminator's \space\space evaluation \space\space of \space\space fake \space\space data\\
Error(a,b):\space\space Error \space\space between \space\space 'a' \space\space and \space\space 'b'\\</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace"> </span><span class="mspace"> </span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">s</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace"> </span><span class="mspace"> </span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">m</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace"> </span><span class="mspace"> </span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">m</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace"> </span><span class="mspace"> </span></span><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">s</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">u</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace"> </span><span class="mspace"> </span></span><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">s</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">u</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace"> </span><span class="mspace"> </span></span><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mspace"> </span><span class="mord"><span class="mspace"> </span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace"> </span><span class="mord"><span class="mspace"> </span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span class="mspace newline"></span></span></span></p>

<p><strong>Discriminator Loss Function</strong></p>

<p>The goal of the <strong>discriminator</strong> is to correctly label generated images as <em>false</em>($0$) and real data samples as <em>true</em>($1$). Therefore, the loss function of <strong>discriminator</strong> would be something like this:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>D</mi></msub><mo>=</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo><mtext>                    </mtext><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{D} = Error(D(x),1) + Error(D(G(z)), 0) \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>

<p>Here, $Error$ is being referring to some function that tells us the distance or difference between two functional parameters.</p>

<p><strong>Generator Loss Function</strong>
The goal of the <strong>generator</strong> is to confuse the <strong>discriminator</strong> as much as possible such that it mislabels the generated images as being true. The loss function of <strong>generator</strong> could be defined as:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>G</mi></msub><mo>=</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo><mtext>                    </mtext><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{G} = Error(D(G(z)), 1) \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space(2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mopen">(</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></span>

<p><strong>Refereces</strong></p>
<ol>
  <li><a href="!https://wiki.pathmind.com/generative-adversarial-network-gan">A Beginner’s Guide to Generatvive Adversarial Networks (GANs)</a></li>
  <li><a href="!https://stats.stackexchange.com/questions/4689/generative-vs-discriminative-models-in-bayesian-context">Stackoverflow</a></li>
  <li><a href="!https://developers.google.com/machine-learning/gan">Generative Adversarial Networks - Google Developers</a></li>
  <li><a href="!https://jaketae.github.io/study/gan-math/">GAN Mathematics</a></li>
</ol>

<p><strong>More to Read</strong></p>
<ol>
  <li><a href="!https://stats.stackexchange.com/questions/12421/generative-vs-discriminative">Stackverflow: Generative v/s Discriminative</a></li>
</ol>

  </div><a class="u-url" href="/kernel/2021/06/30/GAN.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/kernel/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/kernel/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/kernel/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>NLP in day, CV by night.\ Documenting my learnings of Machine Learning.\ Motto: Be Limitless
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/theguywithblacktie" title="theguywithblacktie"><svg class="svg-icon grey"><use xlink:href="/kernel/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/aasinghal" title="aasinghal"><svg class="svg-icon grey"><use xlink:href="/kernel/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/guywithblacktie" title="guywithblacktie"><svg class="svg-icon grey"><use xlink:href="/kernel/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
