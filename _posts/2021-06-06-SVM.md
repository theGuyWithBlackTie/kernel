---
toc: true
layout: post
description: The last blog you need to understand SVM
categories: [Machine Learning]
title: Understanding Support Vector Machine
---

In Machine Learning, out of the many available supervised classification algorithms, Support Vector Machine (SVM) is one of the easiest algorithm and yet sometimes it becomes difficult to grasp due to its little nuances. In this blog, I try to lay down my notes on unboxing the SVM blackbox and make it easy to understand in detail. This blog focusses on entirety of SVM, from its introduction to classification and kernel tricks.

The idea of SVM is simple: The algorithm creates a line or a hyperplane that separates data into different classes. Let's understand how SVM creates the hyperplane and what are its other jargon.

### What is SVM?
Support Vector Machine (SVM) is a supervised ML algorithm that can be used for classification and ***regression as well***. However, it is mostly used in classification problems. In SVM, each data point is plotted in an **n-dimensional** space (**n** = Nos. of features). and classified by finding the best hyperplane that differentiates the classes well.
![]({{ site.baseurl }}/images/svm_hyperplane.png "Fig: 1. SVM Example")

In the above image, data points are plotted in a 2-dimensional space and **solid black** line is the hyperplane that is able to divide the dataset in two classes viz. orange and green color.

{% include alert.html text="Hyperplanes segregates the datasets into two classes only." %}Hyperplanes are **n-1 -dimensional** planes where **n** is total number of features of the dataset. From the above image, data is 2 dimensional and hyperplane divding the space is a 1 dimensional plane.

*Taking it further*: in the above example there is a hyperplane drew that differentiates the dataset in two classes very well. But on keenly thinking, there are other possible hyperplanes too which could be selected that divides the dataset. Something like in the image below:
![]({{ site.baseurl }}/images/svm_multi_hyperplane.png "Fig: 1. Multiple Hyperplanes")

Apart from the **black** coloured hyperplane line, there are other infinite hyperplanes available(to name a few: red, blue, yellow) which could differentiate the dataset too. But which is the best hyperplane among all and what is the criteria to call a hyperplane **best**? This question is answered with the help of **Support Vectors**.

#### What are Support Vectors?
The thumb rule to identify the right hyperplane among infinitly available hyperplanes is: "***Select the hyper-plane which segregates the two classes better***". In this scenario, black coloured hyperplane excellently performed this job. Now consider the scenario below:
