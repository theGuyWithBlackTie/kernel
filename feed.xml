<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://theguywithblacktie.github.io/kernel/feed.xml" rel="self" type="application/atom+xml" /><link href="https://theguywithblacktie.github.io/kernel/" rel="alternate" type="text/html" /><updated>2021-11-01T12:57:24-05:00</updated><id>https://theguywithblacktie.github.io/kernel/feed.xml</id><title type="html">Multiplying Matrices for a living</title><subtitle>NLP in day, CV by night. Documenting my learnings of Machine Learning. Motto: Be Limitless</subtitle><entry><title type="html">Understanding Cross-Entropy Loss and Focal Loss</title><link href="https://theguywithblacktie.github.io/kernel/2021/05/20/cross-entropy-loss.html" rel="alternate" type="text/html" title="Understanding Cross-Entropy Loss and Focal Loss" /><published>2021-05-20T00:00:00-05:00</published><updated>2021-05-20T00:00:00-05:00</updated><id>https://theguywithblacktie.github.io/kernel/2021/05/20/cross-entropy-loss</id><author><name></name></author><summary type="html">In this blogpost we will understand cross-entropy loss and its various different names. Later in the post, we will learn about Focal Loss, a successor of Cross-Entropy(CE) loss that performs better than CE in highly imbalanced dataset setting. We will also implement Focal Loss in PyTorch.</summary></entry><entry><title type="html">Adding Variable Number of Layers in Neural Network</title><link href="https://theguywithblacktie.github.io/kernel/pytorch/2021/05/14/vary-layers-pytorch.html" rel="alternate" type="text/html" title="Adding Variable Number of Layers in Neural Network" /><published>2021-05-14T00:00:00-05:00</published><updated>2021-05-14T00:00:00-05:00</updated><id>https://theguywithblacktie.github.io/kernel/pytorch/2021/05/14/vary-layers-pytorch</id><author><name></name></author><category term="pytorch" /><summary type="html">Consider following code block that defines a fixed 2-layer neural network. Imagine a scenario, where the network has huge number of layers, and typing out each layer manually is just not feasible. An even more notable scenario is when the number of layers of network are not fixed and it depends on some other conigurations. This article deals with these scenarios and lays out solution.</summary></entry><entry><title type="html">Fastpages Notebook Blog Post</title><link href="https://theguywithblacktie.github.io/kernel/jupyter/2020/02/20/test.html" rel="alternate" type="text/html" title="Fastpages Notebook Blog Post" /><published>2020-02-20T00:00:00-06:00</published><updated>2020-02-20T00:00:00-06:00</updated><id>https://theguywithblacktie.github.io/kernel/jupyter/2020/02/20/test</id><author><name></name></author><category term="jupyter" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://theguywithblacktie.github.io/kernel/images/chart-preview.png" /><media:content medium="image" url="https://theguywithblacktie.github.io/kernel/images/chart-preview.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An Example Markdown Post</title><link href="https://theguywithblacktie.github.io/kernel/markdown/2020/01/14/test-markdown-post.html" rel="alternate" type="text/html" title="An Example Markdown Post" /><published>2020-01-14T00:00:00-06:00</published><updated>2020-01-14T00:00:00-06:00</updated><id>https://theguywithblacktie.github.io/kernel/markdown/2020/01/14/test-markdown-post</id><author><name></name></author><category term="markdown" /><summary type="html">Example Markdown Post</summary></entry></feed>